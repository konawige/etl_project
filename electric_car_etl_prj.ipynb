{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4764d679",
   "metadata": {},
   "source": [
    "# ELECTRIC VEHICLES AVAILABLE FOR SALE IN GREATER MONTREAL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97bc64",
   "metadata": {},
   "source": [
    "The goal of the mini project is to show  the implementation of an **ETL process** by gathering the data of different electric vehicles available for sale in Montreal.\n",
    "1. The extraction will be done using webscraping on 3 different dealership websites. For this step **beautifulsoup** and **selenium** will be used\n",
    "2. The data extracted will be merged and cleaned using **Pandas** library\n",
    "3. The resulting data will be then displayed and saved in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e5224",
   "metadata": {},
   "source": [
    "## Install the different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install module\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install webdriver-manager\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb4c3b",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6752b6",
   "metadata": {},
   "source": [
    "### First source: HGregoire website\n",
    "The link to the website is [hgregoire.com](https://www.hgregoire.com/).Our goal is to retrieve all the electric cars available, so we will prepare the url with the appropriate query parameters after setting them on the website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_hgregoire = \"https://www.hgregoire.com/auto-usage?price_sort=1&fuels=%C3%89lectrique%2CHybride\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac46089",
   "metadata": {},
   "source": [
    "Now we can get the data using beautifulsoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74238bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to parse\n",
    "data  = requests.get(url_hgregoire).text\n",
    "soup = BeautifulSoup(data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ddcab6",
   "metadata": {},
   "source": [
    "Then given the different attribures, we can parse the data and extract the following information: name, trim, year, mileage, price and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vehicle_hgreg = pd.DataFrame(columns=[\"Name\", \"Trim\", \"Year\", \"Mileage\", \"Price\", \"Location\", \"Link\"])\n",
    "vehicles = soup.find_all(attrs={\"class\": \"car-details\"})\n",
    "for vehicle in vehicles:\n",
    "    if vehicle.find_parent('div').find('div', attrs={\"class\": \"srp_sold_overlay\"}):\n",
    "        continue\n",
    "    if vehicle.find(attrs={\"class\": \"vehicle-price\"}) is None:\n",
    "        continue\n",
    "        \n",
    "    price = vehicle.find(attrs={\"class\": \"vehicle-price\"}).find(attrs={\"itemprop\": \"price\"})['content']\n",
    "    location = vehicle.find(attrs={\"class\": \"vehicle-location\"}).text.strip()\n",
    "    vehicle_detail_div = vehicle.find(attrs={\"class\": \"vehicle-detail\"})\n",
    "    url = vehicle_detail_div.find('a')['href']\n",
    "    trim = ''\n",
    "    name_span = vehicle_detail_div.find('span', attrs={\"itemprop\": \"name\"})\n",
    "    trim = name_span.find_all('span', {'class': True})[0].text\n",
    "    name_and_year = name_span.find_all('span', {'class': False})[0].text\n",
    "    #first info is the year, and the rest is the car name\n",
    "    year = name_and_year.split(' ')[0]\n",
    "    name_list = name_and_year.split(' ')[1:]\n",
    "    name = ' '.join(name_list)\n",
    "    mileage = vehicle_detail_div.find(attrs={\"itemprop\": \"mileageFromOdometer\"}).find(attrs={\"itemprop\": \"value\"}).text\n",
    "    #print(name_and_year, price , location, url, trim, mileage)\n",
    "    data_vehicle_hgreg = data_vehicle_hgreg.append({\"Name\":name, \"Trim\":trim, \"Year\":year, \"Price\": price, \"Mileage\":mileage, \"Location\": location, \"Link\": url}, ignore_index=True)\n",
    "    \n",
    "data_vehicle_hgreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a76246",
   "metadata": {},
   "source": [
    "### Second source: Montreal Autoprix website\n",
    "The link to the website is [here](https://mtlautoprix.com/).\n",
    "In order to find all the electric vehicles, we should go to the inventory and then choose the appropriate filter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mtlautoprix = \"https://mtlautoprix.com/inventaire-vehicules/?e=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e3f0a",
   "metadata": {},
   "source": [
    "Now we can get the data using beautifulsoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5333d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map  = requests.get(url_mtlautoprix).text\n",
    "soup_map = BeautifulSoup(data_map,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0d034",
   "metadata": {},
   "source": [
    "Then we analyze the data and extract the necessary information. On this website, we can get the name, transmission, year, mileage, and of course the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vehicle_map = pd.DataFrame(columns=[\"Name\", \"Transmission\", \"Year\", \"Mileage\", \"Price\", \"Link\"])\n",
    "vehicles_map = soup_map.find_all(attrs={\"class\": \"info-top-ctn\"})\n",
    "for vehicle in vehicles_map:\n",
    "    name = vehicle.find('div',attrs={\"class\": \"info-brand\"}).find('a').text\n",
    "    url = vehicle.find('div',attrs={\"class\": \"info-brand\"}).find('a')['href']\n",
    "    year = vehicle.find('span', attrs={\"class\": \"year\"}).text\n",
    "    price = vehicle.find('span', attrs={\"class\": \"price-big-part\"}).text + vehicle.find('span', attrs={\"class\": \"price-small-part\"}).text\n",
    "    price = price[:price.find('$')]\n",
    "    mileage = vehicle.find('span', attrs={\"class\": \"mileage\"}).text\n",
    "    transmission = vehicle.find('span', attrs={\"class\": \"trm\"}).text\n",
    "    data_vehicle_map = data_vehicle_map.append({\"Name\":name, \"Transmission\":transmission, \"Year\":year, \"Price\": price, \"Mileage\":mileage, \"Link\": url}, ignore_index=True)\n",
    "    #print(name, year, price, mileage, transmission)\n",
    "    \n",
    "data_vehicle_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a624590",
   "metadata": {},
   "source": [
    "### Third source: Automobile en direct\n",
    "This is another popular car dealer website: [https://www.automobileendirect.com/](https://www.automobileendirect.com/).\n",
    "In order to find all the electric vehicles, we should go to the filter available on the website and select the appropriate options: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63dcaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_aed = \"https://www.automobileendirect.com/auto-usage?fuels=electric,hybrid&page=1&sortBy=date_desc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d40a9",
   "metadata": {},
   "source": [
    "In this case, there are 2 observations to consider:\n",
    "* There is a pagination,so we should find a way to navigate through the different tabs\n",
    "* When getting the page content directly with requests module and beautifulsoup like we did before, we face an issue causing the data of interest to be unavailable after a few iterations.\n",
    "To address this situation, we first use selenium framework to navigate to the website and get the DOM element containing all the cars. Then we use beautifulsoup to parse this DOM element and get the car information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c02654",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vehicle_aed = pd.DataFrame(columns=[\"Name\", \"Description\", \"Year\", \"Mileage\", \"Price\", \"Transmission\", \"Link\"])\n",
    "i=1\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "while True:\n",
    "    url_aed = \"https://www.automobileendirect.com/auto-usage?fuels=electric,hybrid&page=\"+str(i)+\"&sortBy=date_desc\"\n",
    "    driver.get(url_aed)\n",
    "    car_res= driver.find_element_by_class_name('cars__results')\n",
    "    vehicles_aed = car_res.find_elements_by_class_name('carPreview')\n",
    "    # check if ther is any car in the page\n",
    "    if len(vehicles_aed)==0:\n",
    "        break\n",
    "    # parse the element with beautifulsoup\n",
    "    soup_aed = BeautifulSoup(car_res.get_attribute('innerHTML'),\"html.parser\")\n",
    "    list_vehicle = soup_aed.findChildren('a', attrs={\"class\": \"carPreview\"})\n",
    "    for vehicle in list_vehicle:\n",
    "        url = vehicle['href']\n",
    "        name_and_year = vehicle.find(attrs={\"class\": \"carPreview__title\"}).text\n",
    "        year = name_and_year.split(' ')[0]\n",
    "        name_list = name_and_year.split(' ')[1:]\n",
    "        name = ' '.join(name_list)\n",
    "        short_desc = vehicle.find(attrs={\"class\": \"carPreview__short-desc\"}).text\n",
    "        price = vehicle.find(attrs={\"class\": \"carPreview__prices__current\"}).text\n",
    "        if vehicle.find(attrs={\"class\": \"carPreview__location\"}) is not None:\n",
    "            transmission = vehicle.find(attrs={\"class\": \"carPreview__location\"}).text\n",
    "        else:\n",
    "            transmission = ''\n",
    "        mileage = vehicle.find(attrs={\"class\": \"carPreview__kms\"}).text\n",
    "        data_vehicle_aed = data_vehicle_aed.append({\"Name\":name, \"Description\":short_desc, \"Year\":year, \"Price\": price, \"Mileage\":mileage, \"Transmission\": transmission, \"Link\":url}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    i=i+1\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85635b96",
   "metadata": {},
   "source": [
    "The columns we get are name, description, year, mileage, price and transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eff21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_vehicle_aed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd105f43",
   "metadata": {},
   "source": [
    "The Load process did not start yet, but we should add the domain name missing in the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vehicle_aed['Link'] = 'https://www.automobileendirect.com'+data_vehicle_aed['Link']\n",
    "data_vehicle_aed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d1189",
   "metadata": {},
   "source": [
    "### Merge result\n",
    "Once the data are extracted, we merge them to obtain the data we need to transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the 3 dataframes\n",
    "df_concat = pd.concat([data_vehicle_hgreg, data_vehicle_map, data_vehicle_aed], ignore_index=True)\n",
    "\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc42fd",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68614725",
   "metadata": {},
   "source": [
    "### Trim\n",
    "Display all the values in \"Trim\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Trim'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86bfef",
   "metadata": {},
   "source": [
    "There are NAN values in the series. We will replace them by an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0349387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Trim'] = df_concat['Trim'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd01fe",
   "metadata": {},
   "source": [
    "As the trim applies only to the first set of data, we will add them to the name column and delete the trim column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9df036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the 2 columns name and trim\n",
    "df_concat['Name'] = (df_concat['Name'].astype(str) + ' ' + df_concat['Trim'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92370d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bd5b0",
   "metadata": {},
   "source": [
    "All the words in the name column should start with an upper case letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Name'] = df_concat['Name'].str.title()\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285ec3e",
   "metadata": {},
   "source": [
    "All electri vehicles retrieved use an automatic transmission, so the column \"Transmission\" is useless and it can be also deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09752db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_concat.drop(columns=['Trim', 'Transmission'])\n",
    "df_concat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30859ae9",
   "metadata": {},
   "source": [
    "### Description\n",
    "Display all the values in \"Description\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Description'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f09ee4",
   "metadata": {},
   "source": [
    "At this stage we fill NaN values with \"N/A\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6386ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Description'] = df_concat['Description'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526166b",
   "metadata": {},
   "source": [
    "As the description can be relevant, we will not remove the column. A further task will be to analyze all the data sets and see if we can  extract a useful and coherent description from all the web sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad31f4",
   "metadata": {},
   "source": [
    "### Year\n",
    "For this column, we will set a different type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Year'] = df_concat['Year'].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236fe26",
   "metadata": {},
   "source": [
    "### Mileage\n",
    "Display all the values in \"Description\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Mileage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab0137",
   "metadata": {},
   "source": [
    "Convert the column into a string series and then perform some replacement to standardize the data: remove character, space, unit,...As we want to set a integer data type after, the \"N/A\" values are replaced by \"-1\" to identify missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93774768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Mileage'] = df_concat['Mileage'].astype(str)\n",
    "df_concat['Mileage'] = df_concat['Mileage'].str.replace(u'\\xa0', u'')\n",
    "df_concat['Mileage'] = df_concat['Mileage'].str.replace(',', '')\n",
    "df_concat['Mileage'] = df_concat['Mileage'].str.replace('km', '')\n",
    "df_concat['Mileage'] = df_concat['Mileage'].str.replace('KM', '')\n",
    "df_concat['Mileage'] = df_concat['Mileage'].str.replace('N/A', '-1')\n",
    "df_concat['Mileage'] = df_concat['Mileage'].str.replace(' ', '')\n",
    "df_concat['Mileage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd828e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Mileage'] = df_concat['Mileage'].fillna('-1')\n",
    "df_concat['Mileage'] = df_concat['Mileage'].astype(int)\n",
    "df_concat['Mileage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2375163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just confirm we have the good data type\n",
    "df_concat['Mileage'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee907f9",
   "metadata": {},
   "source": [
    "### Price\n",
    "Display all the values in \"Price\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4735c",
   "metadata": {},
   "source": [
    "Convert the column into a string series and then perform some replacement to standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ae6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Price'] = df_concat['Price'].astype(str)\n",
    "df_concat['Price'] = df_concat['Price'].str.replace(u'\\xa0', u'')\n",
    "df_concat['Price'] = df_concat['Price'].str.replace('$', '')\n",
    "df_concat['Price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into a float series\n",
    "df_concat['Price'] = df_concat['Price'].astype(float)\n",
    "df_concat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538f742",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcc42e",
   "metadata": {},
   "source": [
    "For this column, we will just mark the NaN values as \"to be determined\", and see if the location can be extracted from all the sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Location'] = df_concat['Location'].fillna('TBD')\n",
    "df_concat['Location'] = df_concat['Location'].astype('str')\n",
    "df_concat['Location'] = df_concat['Location'].str.replace('St', 'Saint')\n",
    "df_concat['Location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c129be",
   "metadata": {},
   "source": [
    "## Load\n",
    "The resulting dataframe is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce30f3",
   "metadata": {},
   "source": [
    "We can load results in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv(\"electric_vehicles_etl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e6467",
   "metadata": {},
   "source": [
    "## Next\n",
    "We complete the ETL process of obtaining the electric vehicles available to sell. Some improvements can be made to the project:\n",
    "* Improve the web scraping section to obtain missing information like location and description for certain sources\n",
    "* Create an endpoint to make available the data obtained from the ETL process\n",
    "* Gather other useful information ( like images, color) to build a small web application and display the resuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
